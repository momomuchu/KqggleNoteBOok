{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  **Analisis Sentimen Ulasan Aplikasi MyXL dengan SVM di Google Play Store**","metadata":{}},{"cell_type":"markdown","source":"Review pada Google Play Store merupakan salah satu fitur yang digunakan untuk memberikan suatu penilaian terhadap suatu aplikasi. MyXL merupakan aplikasi self-service yang diberikan oleh PT XL Axiata Tbk pada Google Play Store yang berguna dalam proses memudahkan pengguna dalam melakukan kegiatan yang diberikan fitur-fitur seperti aktivasi paket internet, cek pulsa, cek sisa kuota, layanan FAQ dan Live Chat, dll. Namun review pada aplikasi MyXL tersebut hanya berupa teks tanpa arti tertentu dan terdapat beberapa pengguna yang memberikan rating yang tinggi namun ulasan yang diberikan merupakan review negatif, untuk itu diperlukan analisis yang dapat mengklasifikasikan review sebagai sentimen pengguna. \n\nDalam penelitian ini dilakukan tahap scraping untuk pengumpulan data informasi ulasan pengguna aplikasi MyXL, setelah itu melakukan pelabelan terhadap data dan dikategorisasikan kedalam kelas positif, negatif dan netral. Selanjutnya text preprocessing untuk mengolah data dengan menyeleksi data dan mengubahnya menjadi data yang lebih terstruktur agar dapat digunakan sesuai kebutuhan penelitian. Setelah mendapatkan data hasil text preprocessing dilakukan pembobotan kata dengan memberikan nilai pada suatu kata dalam sebuah dokumen menggunakan metode Term Frequency â€“ Inverse Document Frequency (TF-IDF). Kemudian dilakukan pengolahan dengan mengklasifikasi menggunakan algoritma Support Vector Machine (SVM).","metadata":{}},{"cell_type":"markdown","source":"**Manfaat dilakukan analisis sentimen adalah:**\n1. Hasil analisis sentimen dapat dilihat oleh pengguna aplikasi MyXL dan agar dapat mengetahui opini pengguna lain.\n2. Sebagai bahan pertimbangan PT XL Axiata Tbk untuk menyempurnakan dan mengimprovisasi aplikasi MyXL dengan hasil analisis yang didapatkan.","metadata":{}},{"cell_type":"markdown","source":"**1. Scraping Data**\n \nScraping data dilakukan dengan mengumpukan data ulasan pengguna aplikasi MyXL dari Google Play Store menggunakan bantuan dari library google-play-scraper dan IDE Google Collab. Data yang diambil berupa nama pemberi ulasan, nilai bintang yang diberikan, waktu ulasan dikirim dan isi review ulasan.","metadata":{}},{"cell_type":"code","source":"!pip install google-play-scraper","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google_play_scraper import app\nimport pandas as pd\nimport numpy as np\nfrom google_play_scraper import Sort, reviews","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result, continuation_token = reviews(\n    'com.apps.MyXL',\n    lang='id', \n    country='id', \n    sort=Sort.MOST_RELEVANT, \n    count=1000, \n    filter_score_with=None\n)\ndf_busu = pd.DataFrame(np.array(result),columns=['review'])\ndf_busu = df_busu.join(pd.DataFrame(df_busu.pop('review').tolist()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = df_busu[['userName', 'score','at', 'content']]\nsorted_df = new_df.sort_values(by='at', ascending=False) \nsorted_df.to_csv(\"Ulasan My XL 1000 Data.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Pelabelan Dataset**\n\nPelabelan dataset dilakukan secara manual terhadap pelabelan data kedalam kelas kategori positif, negatif atau netral. Proses ini akan dilakukan dengan bantuan ahli bahasa Indonesia dan dilakukan pelabelan oleh setidaknya lebih dari dua orang.\n","metadata":{}},{"cell_type":"markdown","source":"**3. Case Folding**\n\nCase folding dilakukan pengubahan seluruh huruf menjadi kecil (lowercase) yang ada pada dokumen. Tahap ini akan dibantu dengan bantuan library RegEx.","metadata":{}},{"cell_type":"code","source":"import re\ndef cleaningulasan(ulasan):\n  ulasan = re.sub(r'@[A-Za-a0-9]+',' ',ulasan)\n  ulasan = re.sub(r'#[A-Za-z0-9]+',' ',ulasan)\n  ulasan = re.sub(r\"http\\S+\",' ',ulasan)\n  ulasan = re.sub(r'[0-9]+',' ',ulasan)\n  ulasan = re.sub(r\"[-()\\\"#/@;:<>{}'+=~|.!?,_]\", \" \", ulasan)\n  ulasan = ulasan.strip(' ')\n  return ulasan\nulasan['Cleaning']= ulasan['Ulasan'].apply(cleaningulasan)\n\ndef clearEmoji(ulasan):\n    return ulasan.encode('ascii', 'ignore').decode('ascii')\nulasan['HapusEmoji']= ulasan['Cleaning'].apply(clearEmoji)\n\ndef replaceTOM(ulasan):\n    pola = re.compile(r'(.)\\1{2,}', re.DOTALL)\n    return pola.sub(r'\\1', ulasan)\nulasan['3/Lebih']= ulasan['HapusEmoji'].apply(replaceTOM)\n\ndef casefoldingText(ulasan):\n  ulasan = ulasan.lower()\n  return ulasan\nulasan['CaseFolding']= ulasan['3/Lebih'].apply(casefoldingText)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Tokenizing**\n\nHasil proses case folding, kalimat akan diproses dengan menguraikannya menjadi token-token atau kata-kata. Pada tahap ini akan dibantu dengan library NLTK.","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\ndef tokenizingText(ulasan):\n  ulasan = word_tokenize(ulasan)\n  return ulasan\nulasan['Tokenizing']= ulasan['CaseFolding'].apply(tokenizingText)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5. Formalisasi**\n\nTahap formalisasi dilakukan untuk pengubah penggunaan kata tidak baku menjadi baku sesuai dengan KBBI. Proses akan menggunakan file dataset slangwords yang berisi kata slang yang nanti akan diubah menjadi baku. Tahap ini dibantu dengan library RegEx. ","metadata":{}},{"cell_type":"code","source":"def convertToSlangword(ulasan):\n    kamusSlang = eval(open(\"slangwords.txt\").read())\n    pattern = re.compile(r'\\b( ' + '|'.join (kamusSlang.keys())+r')\\b')\n    content = []\n    for kata in ulasan:\n        filterSlang = pattern.sub(lambda x: kamusSlang[x.group()],kata)\n        content.append(filterSlang.lower())\n    ulasan = content\n    return ulasan\n\nulasan['Formalisasi'] = ulasan['Tokenizing'].apply(convertToSlangword)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6. Stopword Removal**\n\nHasil proses formalisasi kemudian akan dilakukan seleksi kata yang tidak penting dan menghapus kata tersebut. Tahap ini dibantu dengan library NLTK.","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\ndaftar_stopword = stopwords.words('indonesian')\n# ---------------------------- manualy add stopword  ------------------------------------\n# append additional stopword\ndaftar_stopword.extend([\"yg\",\"dg\",\"rt\"])\ndaftar_stopword = set(daftar_stopword)\n\ndef stopwordText(words):\n return [word for word in words if word not in daftar_stopword]\n\nulasan['Stopword Removal'] = ulasan['Formalisasi'].apply(stopwordText)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**7. Stemming**\n\nProses stemming dilakukan perubahan kata yang berimbuhan menjadi kata dasar. Tahap ini dibantu dengan library Sastrawi dan Swifter.","metadata":{}},{"cell_type":"code","source":"from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\nimport swifter\n\nfactory = StemmerFactory()\nstemmer = factory.create_stemmer()\n\ndef stemmed_wrapper(term):\n    return stemmer.stem(term)\n\nterm_dict = {}\n\nfor document in ulasan['Stopword Removal']:\n    for term in document:\n        if term not in term_dict:\n            term_dict[term] = ' '\n\nfor term in term_dict:\n    term_dict[term] = stemmed_wrapper(term)\n    print(term,\":\" ,term_dict[term])\n    \ndef stemmingText(document):\n    return [term_dict[term] for term in document]\n\nulasan['Stemming'] = ulasan['Stopword Removal'].swifter.apply(stemmingText)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**8. Pembobotan Kata dengan TF-IDF**\n\nPada tahap ini dilakukan pembobotan kata dari hasil stemming dengan metode Term Inverse Document Frequency (TF-IDF).Metode TF-IDF digunakan untuk mengetahui seberapa sering suatu kata muncul di dalam dokumen. Tahap ini dibantu dengan library sklearn.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nX = df['Stemming']\nY = df['Sentimen']\n\nx_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2)\n\nvectorizer = TfidfVectorizer()\nx_train = vectorizer.fit_transform(x_train)\nx_test = vectorizer.transform(x_test)\nEncoder = LabelEncoder()\ny_train = Encoder.fit_transform(y_train)\ny_test = Encoder.fit_transform(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**9. Klasifikasi dengan SVM**\n\nKlasifikasi ulasan pengguna dilakukan menggunakan algoritma Support Vector Machine yang akan dibantu dengan library Scikit-Learn. Proses klasifikasi menggunakan nilai data latih dan data uji sebesar 80%:20%, dilakukan percobaan sebanyak 5x dan kernel akan menggunakan kernel rbf dan kernel linear.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn import svm\n\nSVM = svm.SVC(kernel='rbf')    #Jika dengan Kernel RBF\nSVM = svm.SVC(kernel='linear') #Jika dengan Kernel Linear\nSVM.fit(x_train,y_train)\n\nacc_score = cross_val_score(SVM, x_train, y_train, cv=5, scoring='accuracy')\npre_score = cross_val_score(SVM, x_train, y_train, cv=5, scoring='precision_macro')\nrec_score = cross_val_score(SVM, x_train, y_train, cv=5, scoring='recall_macro')\nf_score = cross_val_score(SVM, x_train, y_train, cv=5, scoring='f1_macro')\n\nprint('Hasil Accuracy : %s' % (acc_score))\nprint('Hasil Rata - Rata Accuracy : %s' % acc_score.mean())\nprint('Hasil Precision : %s' % (pre_score))\nprint('Hasil Rata - Rata Precision : %s' % pre_score.mean())\nprint('Hasil Recall : %s' % (rec_score))\nprint('Hasil Rata - Rata Recall : %s' % rec_score.mean())\nprint('Hasil F-Measure : %s' % (f_score))\nprint('Hasil Rata - Rata F-Measure : %s' % f_score.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hasil Klasifikasi","metadata":{}},{"cell_type":"markdown","source":"Hasil klasifikasi pertama didapatkan bahwa pada pengujian pertama penggunaan data utuh berjumlah 1000 data dengan penggunaan data seimbang 480 data pada sentimen 3 kelas didapatkan bahwa hasil akurasi terbaik pada data utuh dengan pengujian kernel Linear menghasilkan nilai akurasi sebesar 71%.Hal ini dapat dikatan bahwa pada hasil pengujian ini semakin banyak data yang digunakan maka hasil yang didapatkan akan semakin tinggi, tanpa memedulikan data tersebut tidak seimbang atau seimbang.\n\n\n\nHasil klasifikasi kedua akan diuji nilai kernel terbaik dengan penggunaan sentimen 3 kelas terbaik sebelumnya dengan penggunaan sentimen 2 kelas, mendapatkan hasil bahwa dari pengujian yang dilakukan penggunaan nilai kernel pada kedua skenario hasil tertinggi menggunakan kernel linear yang sebesar 89% pada sentimen 2 kelas. Dapat dikatakan bahwa nilai kernel linear paling cocok untuk digunakan dalam pengujian ini karena bisa mendapatkan hasil lebih baik dari penggunaan kernel rbf.\n\n\n\nKetiga dilakukan pengujian evaluasi performa pada hasil klasifikasi sebelumnya, didapatkan utnuk evaluasi performa tersebut hasil terbaik dari pengujian pada sentimen 2 kelas didapatkan nilai rata-rata accuracy sebesar 89%, sedangkan pada pengujian sentimen 3 kelas hanya sebesar 71%. Nilai rata-rata presicion terbaik pada pengujian sentimen 2 kelas sebesar 90%, sedangkan pada pengujian sentimen 3 kelas hanya sebesar 70%. Nilai rata-rata recall terbaik pada pengujian sentimen 2 kelas sebesar 76%, sedangkan pada pengujian sentimen 3 kelas hanya sebesar 55%. Nilai rata-rata f-measure terbaik pada pengujian sentimen 2 kelas sebesar 80%, sedangkan pada pengujian sentimen 3 kelas hanya sebesar 58%. Penggunaan sentimen 2 kelas mendapatkan hasil akurasi lebih baik dibandingkan dengan sentimen 3 kelas. Hal ini dikarenakan proses klasifikasi pada sentimen 3 kelas yang kompleks karena terdapat 3 kategori kelas yaitu negatif, netral dan positif, sedangkan pada sentimen 2 kelas tidak membutuhkan proses  klasifikasi yang kompleks karena hanya terdapat 2 kategori kelas yaitu negatif dan positif saja.\n\n\n\nDapat disimpulkan bahwa penggunaan data yang lebih banyak dapat membantu untuk mendapatkan hasil klasifikasi lebih maksimal, penggunaan kernel yang digunakan akan sangat berpengaruh terhadap hasil akurasi maka dari perlu untuk mengguji dengan berbagai kernel agar dapat mengetahui kernel terbaik, dan penggunaan kelas jumlah kelas akan mempengaruhi proses klasifikasi semakin banyak kelas yang digunakan maka proses akan semakin komplek dan hasil akurasi menurun.\n\nUntuk hasil klasifikasi ini dapat dilihat melalui visualisasi menggunakan Google Data Studio berikut:\n\nhttps://datastudio.google.com/u/0/reporting/1fc0efc9-fa9e-4554-8b82-b959cf5e9815/page/4A5wC","metadata":{}},{"cell_type":"markdown","source":"# **Akhir Artikel**","metadata":{}},{"cell_type":"markdown","source":"Semoga dari penulisan artikel ini dapat membantu kalian yang membutuhkan referensi terkait hal analisis sentimen. Kurang lebihnya mohon maaf dan terima kasih!","metadata":{}}]}